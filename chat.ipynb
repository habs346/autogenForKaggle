{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot\n",
    "In this note book we build a chat bot step by step using a free api from groqcloud\n",
    "\n",
    "## 1. install the nessary pakages\n",
    "we use the framework from Microsoft, AutoGen, which requires Python version >= 3.8, < 3.13, to build the workflow. Then, the Groq Python library is also\n",
    "needed for using models on Groq cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install groq\n",
    "! pip install autogen-agentchat~=0.2\n",
    "! pip install \"autogen-agentchat[retrievechat]~=0.2\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the free api from [Groq cloud](https://console.groq.com/playground) \n",
    "There is a very good [blog](https://www.geeksforgeeks.org/groq-api-with-llama-3/) demostrating the process step by step \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api =\"you grop api here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Set docs paths\n",
    "\n",
    "local documents or online\n",
    "\n",
    "Accepted file formats for `docs_path`:\n",
    "['txt', 'json', 'csv', 'tsv', 'md', 'html', 'htm', 'rtf', 'rst', 'jsonl', 'log', 'xml', 'yaml', 'yml', 'pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_path=[\"data\\data_description.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Set the LLM agents representing user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import autogen\n",
    "import groq\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "from autogen import AssistantAgent\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "import tempfile\n",
    "# directory to store the code files\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "# code executor config for running code in local environment but best run llm generate code in docker environment more details in autogen tutorials.code_executon\n",
    "executor = LocalCommandLineCodeExecutor(\n",
    "    timeout=10,  # Timeout for each code execution in seconds.\n",
    "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
    ")\n",
    "\n",
    "# set the model of LLM\n",
    "config1={\"config_list\": [{\"model\": \"llama-3.2-90b-text-preview\", \"api_key\": groq_api,\"api_type\": \"groq\",}]} \n",
    "config2={\"config_list\": [{\"model\": \"llama-3.2-11b-vision-preview\", \"api_key\": groq_api,\"api_type\": \"groq\",}]}\n",
    "# set the admin of the assistant agents\n",
    "user_proxy=autogen.UserProxyAgent(\n",
    "    name=\"admin\",\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "    code_execution_config={\"executor\": executor},\n",
    ")\n",
    "# set the doc analyzer of the assistant agents\n",
    "doc_proxy=RetrieveUserProxyAgent(\n",
    "    name=\"plan\",\n",
    "    retrieve_config={\n",
    "        \"task\": \"qa\",\n",
    "        \"docs_path\": docs_path,\n",
    "        \"get_or_create\": True, \n",
    "        \"overwrite\": True,\n",
    "    },\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    code_execution_config={\"executor\": executor},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prompts for assitant agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_requirment =\"\"\"You are a helpful assistant. You can ananlyze the document and give requirments to the code writer based on document.\"\"\"\n",
    "message_code_write=\"\"\"You are a helpful AI assistant.\n",
    "Solve tasks using your coding and language skills.\n",
    "In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n",
    "1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n",
    "2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\n",
    "Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\n",
    "When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\n",
    "If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n",
    "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n",
    "Reply 'TERMINATE' in the end when everything is done.\n",
    "\"\"\"\n",
    "message_check_agent=\"\"\" You are a helpful assistant. You can check the output written by others and give feedback based on the code.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Set LLM agengts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_agent = AssistantAgent(\n",
    "    name=\"req\",\n",
    "    system_message=message_requirment,\n",
    "    llm_config=config2,\n",
    ")\n",
    "code_agent = AssistantAgent(\n",
    "    name=\"code\",\n",
    "    system_message=message_code_write,\n",
    "    llm_config=config1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Build chat group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the description of the agents so that the groupchat manager can understand the role of the agents\n",
    "req_agent.description=\"analyze the document and give requirments to the code writer based on document.\"\n",
    "code_agent.description=\"Solve tasks using coding and language skills.\"\n",
    "# build the groupchat \n",
    "group_chat = autogen.GroupChat(\n",
    "    agents=[req_agent, code_agent,doc_proxy],\n",
    "    messages=[],\n",
    "    send_introductions=True,\n",
    "    speaker_selection_method=\"round_robin\", # select the speaker in round robin fashion more details in autogen tutorials\n",
    ")\n",
    "# set the groupchat manager\n",
    "manager = autogen.GroupChatManager(groupchat=group_chat, llm_config=config1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Chat (only based on doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"can you predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable.train data is in .\\data\\train.csv and test data is in .\\data\\test.csv. give me a csv file with the Id and SalePrice columns in the .\\data.\"\n",
    "chat_resluts=doc_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=doc_proxy.message_generator,\n",
    "    problem=question,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
